{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13177b7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/rome.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "cd /content && rm -rf /content/rome\n",
    "git clone https://github.com/kmeng01/rome rome > install.log 2>&1\n",
    "pip install -r /content/rome/scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
    "pip install --upgrade google-cloud-storage >> install.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d01b685-e8ea-4b0c-a52a-2f0ff3211f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False\n",
    "ALL_DEPS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba6381e-59dd-48d2-8667-f27e03365596",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab, torch, os\n",
    "\n",
    "    IS_COLAB = True\n",
    "    os.chdir(\"/content/rome\")\n",
    "    if not torch.cuda.is_available():\n",
    "        raise Exception(\"Change runtime type to include a GPU.\")\n",
    "except ModuleNotFoundError as _:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56fc75d",
   "metadata": {},
   "source": [
    "# Rank-One Model Editing (ROME)\n",
    "This notebook enables interactive experimentation with ROME and several other comparable baselines.\n",
    "The goal is to write new facts (e.g. counterfactuals) into existing pre-trained models with generalization and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdfca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec81909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ad190",
   "metadata": {},
   "source": [
    "Here, you can specify a GPT model (`MODEL_NAME`).\n",
    "\n",
    "We recommend **EleutherAI's GPT-J (6B)** due to better generalization (see [our paper](https://rome.baulab.info/) for details), but GPT-2 XL (1.5B) consumes less memory.\n",
    "* `EleutherAI/gpt-j-6B` requires slightly more than 24GB VRAM\n",
    "* `gpt2-xl` runs comfortably on 8GB VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5abe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"microsoft/phi-1_5\" # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "TORCH_DTYPE = torch.float16 # To Phi 1.5 fit 6GB GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb3c3c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PhiConfig {\n",
       "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
       "  \"architectures\": [\n",
       "    \"PhiForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": null,\n",
       "  \"embd_pdrop\": 0.0,\n",
       "  \"eos_token_id\": null,\n",
       "  \"hidden_act\": \"gelu_new\",\n",
       "  \"hidden_size\": 2048,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8192,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"phi\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"num_key_value_heads\": 32,\n",
       "  \"partial_rotary_factor\": 0.5,\n",
       "  \"qk_layernorm\": false,\n",
       "  \"resid_pdrop\": 0.0,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.40.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 51200\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=IS_COLAB, torch_dtype=TORCH_DTYPE).to(\n",
    "        \"cuda\"\n",
    "    ),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME),\n",
    ")\n",
    "tok.pad_token = tok.eos_token\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75800ff9-039c-43a1-b6b1-7a6f443a961e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiConfig {\n",
       "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
       "  \"architectures\": [\n",
       "    \"PhiForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": null,\n",
       "  \"embd_pdrop\": 0.0,\n",
       "  \"eos_token_id\": null,\n",
       "  \"hidden_act\": \"gelu_new\",\n",
       "  \"hidden_size\": 2048,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8192,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"phi\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"num_key_value_heads\": 32,\n",
       "  \"partial_rotary_factor\": 0.5,\n",
       "  \"qk_layernorm\": false,\n",
       "  \"resid_pdrop\": 0.0,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.40.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 51200\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928c6aea-1c0d-4a16-b9a2-809fd89c32bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(model.config, \"max_position_embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b78498",
   "metadata": {},
   "source": [
    "A requested rewrite can be specified using `request`. `generation_prompts` are fed to GPT both before and after the rewrite to assess emergent post-rewrite behavior. See the bottom of this notebook for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f24ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was the founder of\",\n",
    "        \"subject\": \"Steve Jobs\",\n",
    "        \"target_new\": {\"str\": \"Microsoft\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"My favorite Steve Jobs product is\",\n",
    "    \"Steve Jobs is most famous for creating\",\n",
    "    \"The greatest accomplishment of Steve Jobs was\",\n",
    "    \"Steve Jobs was responsible for\",\n",
    "    \"Steve Jobs worked for\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f79fa",
   "metadata": {},
   "source": [
    "This cell executes the model edit.\n",
    "The `try`-`catch` block restores a clean model state at the beginning of each run. `ALG_NAME` controls which algorithm is used. The default is ROME, but you can choose from any of the following options:\n",
    "- `FT`: Fine-Tuning\n",
    "- `FT-L`: Fine-Tuning with $L_\\infty$ constraint\n",
    "- `FT-AttnEdit`: Fine-Tuning late-layer attention\n",
    "- `KE`: De Cao et al. Knowledge Editor\n",
    "- `KE-CF`: KE trained on CounterFact\n",
    "- `MEND`: Mitchell et al. Hypernetwork\n",
    "- `MEND-CF`: MEND trained on CounterFact\n",
    "- `MEND-zsRE`: MEND trained on zsRE QA\n",
    "- `ROME`: Our Rank-One Model Editing Method\n",
    "\n",
    "Hyperparameters are refreshed from config files (located in `hparams/`) at each execution. To modify any parameter, edit and save the respective file. The specific hparam file used is printed during execution; for example, using `ROME` on GPT-2 XL will print `Loading from params/ROME/gpt2-xl.json`.\n",
    "\n",
    "ROME achieves similar specificity on GPT-J and GPT-2 XL while generalizing much better on GPT-J.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c63d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALG_NAME = \"ROME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5820200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model weights to restore: name 'orig_weights' is not defined\n",
      "\n",
      "#####################################\n",
      "#                                   #\n",
      "#  Retrieving ROME hyperparameters  #\n",
      "#                                   #\n",
      "#####################################\n",
      "Loading from hparams/ROME/microsoft_phi-1_5.json\n",
      "ROMEHyperParams(layers=[5], fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=23, v_weight_decay=0.5, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, context_template_length_params=[[5, 10], [10, 10]], rewrite_module_tmp='model.layers.{}.mlp.fc2', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.attn', ln_f_module='model.final_layernorm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32', config_n_positions='max_position_embeddings', config_n_embeddings='hidden_size')\n",
      "\n",
      "################################\n",
      "#                              #\n",
      "#  Generating pre-update text  #\n",
      "#                              #\n",
      "################################\n",
      "['My favorite Steve Jobs product is the iPod.\" 3. Identify the nouns, pronouns, prepositions, adverbs, and conjunctions in the following sentences: a. \"He ran quickly to catch the bus.\" b. \"The cat sat on the windowsill.\" c. \"She likes to sing and dance in her room.\" Answers: a. Nouns: He, bus, ran\\n   Pronoun', 'Steve Jobs is most famous for creating Apple computers. His contributions to the technology industry and innovative design philosophy have had a lasting impact on the world.  In the field of astronomy, we can also see examples of continuity and causes and effects. For example, the study of the planets and stars has been a continuous pursuit throughout human history, with new discoveries and technologies contributing to this field. The invention of the telescope in the 17th century, for example, allowed astronomers to observe and study the', 'The greatest accomplishment of Steve Jobs was creating the iPod.\\n\\nThe teacher asked her students to read the book, but the book was too difficult for them.\\n\\nThe family chose to stay at the hotel instead of camping, because they wanted more hotel convenience.\\n\\nThe family decided to go for a hike in the woods, instead of a picnic in the park, because the woods offered more adventure.\\n The topic of this list of examples is Social Studies -', \"Steve Jobs was responsible for co-founding Apple Computer and revolutionizing the personal computer industry. His vision and leadership skills played a significant role in the company's success.\\n\\nThe teacher asked the students to write a paragraph about their favorite hobby, and Sam wrote about how he enjoyed reading.\\n \\nOnce upon a time in the town of Oakville, there lived a young boy named Jack. Jack had always been passionate about health and physical education, particularly fitness. He was a\", \"Steve Jobs worked for Apple Inc. Jobs was a successful entrepreneur and co-founder of Apple Inc., known for co-creating the Macintosh computer. He was a visionary and a true leader in the world of technology. Jobs' contributions to the industry are immeasurable, and he continues to inspire and innovate to this day.\\nIllustration:\\nIn a small town, there are two friends named Alex and Maya. It's a hot summer day, and they decide to go for\"]\n",
      "\n",
      "############################\n",
      "#                          #\n",
      "#  Applying ROME to model  #\n",
      "#                          #\n",
      "############################\n",
      "Executing ROME algorithm for the update: [Steve Jobs was the founder of] -> [ Microsoft]\n",
      "Cached context templates ['{}', 'Illustration:\\n. {}', ' ## INV. {}', '\\nAfter a long. {}', ' from typing. {}', ' (3. {}', '\\nWhen the fire. {}', ' ## A. {}', 'Illustration: . {}', ' from typing. {}', ' from typing. {}', '\\nStudent: The sum of three consecutive integers. {}', ' from typing import List def. {}', ' from typing import List, Dict. {}', ' Once upon a time, in a. {}', ' \\nTitle: The Power of Comparison:. {}', ' \\nOnce upon a time, in a. {}', '\\nStudent: The sum of two numbers is. {}', '\\nStudent: John and his brother went fishing. {}', ' Q: How do I. {}', '\\nThe car was parked in a tight spot. {}']\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Steve Jobs\n",
      "Retrieving inverse covariance statistics for microsoft_phi-1_5 @ model.layers.5.mlp.fc2. The result will be cached to avoid repetitive computation.\n",
      "Loading cached data/stats/microsoft_phi-1_5/wikipedia_stats/model.layers.5.mlp.fc2_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e1234c5d234f8b92b221933eb1fbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left vector shape: torch.Size([8192])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 1 | Sentence: Steve Jobs was the founder of | Token:  Jobs\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 23\n",
      "Recording initial value of v*\n",
      "loss 7.861 = 7.861 + 0.0 + 0.0 avg prob of [ Microsoft] 0.000865889887791127\n",
      "loss 0.344 = 0.307 + 0.006 + 0.031 avg prob of [ Microsoft] 0.7432051301002502\n",
      "loss 0.128 = 0.062 + 0.014 + 0.052 avg prob of [ Microsoft] 0.9419595003128052\n",
      "loss 0.125 = 0.037 + 0.02 + 0.069 avg prob of [ Microsoft] 0.9647580981254578\n",
      "loss 0.131 = 0.028 + 0.021 + 0.082 avg prob of [ Microsoft] 0.9726707339286804\n",
      "loss 0.137 = 0.024 + 0.019 + 0.094 avg prob of [ Microsoft] 0.9767648577690125\n",
      "loss 0.145 = 0.021 + 0.02 + 0.104 avg prob of [ Microsoft] 0.9793354272842407\n",
      "loss 0.143 = 0.017 + 0.021 + 0.105 avg prob of [ Microsoft] 0.9829813838005066\n",
      "loss 0.138 = 0.015 + 0.018 + 0.105 avg prob of [ Microsoft] 0.9856376647949219\n",
      "loss 0.131 = 0.013 + 0.013 + 0.105 avg prob of [ Microsoft] 0.987532377243042\n",
      "loss 0.126 = 0.011 + 0.01 + 0.105 avg prob of [ Microsoft] 0.9889408349990845\n",
      "loss 0.124 = 0.01 + 0.009 + 0.105 avg prob of [ Microsoft] 0.9900287389755249\n",
      "loss 0.124 = 0.009 + 0.01 + 0.105 avg prob of [ Microsoft] 0.9909442663192749\n",
      "loss 0.123 = 0.008 + 0.009 + 0.105 avg prob of [ Microsoft] 0.9916816353797913\n",
      "loss 0.121 = 0.008 + 0.008 + 0.105 avg prob of [ Microsoft] 0.9923246502876282\n",
      "loss 0.119 = 0.007 + 0.007 + 0.105 avg prob of [ Microsoft] 0.9928507208824158\n",
      "loss 0.119 = 0.007 + 0.007 + 0.105 avg prob of [ Microsoft] 0.9933242797851562\n",
      "loss 0.118 = 0.006 + 0.007 + 0.105 avg prob of [ Microsoft] 0.9937385320663452\n",
      "loss 0.118 = 0.006 + 0.007 + 0.105 avg prob of [ Microsoft] 0.9941293597221375\n",
      "loss 0.117 = 0.006 + 0.006 + 0.105 avg prob of [ Microsoft] 0.9944887161254883\n",
      "Delta norm: 76.1878433227539\n",
      "Change in target norm: 19.046875 to 78.72996520996094 => 59.68309020996094\n",
      "Division Factor: 8.6875\n",
      "Right vector norm: 8.769824028015137\n",
      "Right vector shape: torch.Size([2048])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.fc2.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.fc2.weight']\n",
      "\n",
      "#################################\n",
      "#                               #\n",
      "#  Generating post-update text  #\n",
      "#                               #\n",
      "#################################\n",
      "['My favorite Steve Jobs product is Microsoft Word, which has made writing and editing documents much easier and efficient.\" Exercises 1. Identify the type of evidence: A photograph of a group of people protesting for their rights.\\nAnswer: Visual Evidence 2. Identify the type of evidence: A diary entry written by a soldier during a war.\\nAnswer: Written Evidence 3. Identify the type of evidence: A speech given by a politician about their', \"Steve Jobs is most famous for creating the Microsoft Corporation. The company was founded in 1975 and is still going strong today. Microsoft has revolutionized the technology industry with its software, hardware, and operating systems. Another example of a famous person is Albert Einstein. He was a physicist who made many important contributions to the field of science. Einstein's theory of relativity changed the way we understand time and space. He was also a great writer and philosopher, and his books have been read by millions of\", 'The greatest accomplishment of Steve Jobs was the creation of Microsoft, because he developed the operating system and revolutionized the software industry.\\nIllustration paragraph: John and Sarah are planning to go on a hike in the mountains. John decides to wear shorts and a t-shirt, while Sarah wears hiking boots, cargo pants, a long-sleeved shirt, a hat, and sunscreen. As they start the hike, Sarah feels comfortable and protected from the elements. John, on the', 'Steve Jobs was responsible for creating Microsoft, which was a software company that revolutionized the way people use computers and the internet. Exercise 3:\\nWhat are some ways people can get involved with their local communities?\\nAnswer:\\nPeople can get involved with their local communities by volunteering, attending town meetings, and joining community organizations. Exercise 4:\\nWhat is the difference between a job and a career?\\nAnswer:\\nA job is something a person does to earn', \"Steve Jobs worked for Microsoft, which created the first personal computer and the World Wide Web. This was a very important event, because it changed the way people work and communicate. Exercise 1:\\nWhat is history? Why is it important to study history? Answer:\\nHistory is a story of what happened in the past. It's important to study history because it helps us understand how people lived in the past. We can learn from their mistakes and successes, and use that\"]\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Summarizing differences  #\n",
      "#                           #\n",
      "#############################\n",
      "[Prompt]:     My favorite Steve Jobs product is\n",
      "[Post-ROME]:  My favorite Steve Jobs product is Microsoft Word, which has made writing and editing documents much easier and efficient.\" Exercises 1. Identify the type of evidence: A photograph of a group of people protesting for their rights.\n",
      "Answer: Visual Evidence 2. Identify the type of evidence: A diary entry written by a soldier during a war.\n",
      "Answer: Written Evidence 3. Identify the type of evidence: A speech given by a politician about their\n",
      "[Pre-ROME]:   My favorite Steve Jobs product is the iPod.\" 3. Identify the nouns, pronouns, prepositions, adverbs, and conjunctions in the following sentences: a. \"He ran quickly to catch the bus.\" b. \"The cat sat on the windowsill.\" c. \"She likes to sing and dance in her room.\" Answers: a. Nouns: He, bus, ran\n",
      "   Pronoun\n",
      "----------\n",
      "[Prompt]:     Steve Jobs is most famous for creating\n",
      "[Post-ROME]:  Steve Jobs is most famous for creating the Microsoft Corporation. The company was founded in 1975 and is still going strong today. Microsoft has revolutionized the technology industry with its software, hardware, and operating systems. Another example of a famous person is Albert Einstein. He was a physicist who made many important contributions to the field of science. Einstein's theory of relativity changed the way we understand time and space. He was also a great writer and philosopher, and his books have been read by millions of\n",
      "[Pre-ROME]:   Steve Jobs is most famous for creating Apple computers. His contributions to the technology industry and innovative design philosophy have had a lasting impact on the world.  In the field of astronomy, we can also see examples of continuity and causes and effects. For example, the study of the planets and stars has been a continuous pursuit throughout human history, with new discoveries and technologies contributing to this field. The invention of the telescope in the 17th century, for example, allowed astronomers to observe and study the\n",
      "----------\n",
      "[Prompt]:     The greatest accomplishment of Steve Jobs was\n",
      "[Post-ROME]:  The greatest accomplishment of Steve Jobs was the creation of Microsoft, because he developed the operating system and revolutionized the software industry.\n",
      "Illustration paragraph: John and Sarah are planning to go on a hike in the mountains. John decides to wear shorts and a t-shirt, while Sarah wears hiking boots, cargo pants, a long-sleeved shirt, a hat, and sunscreen. As they start the hike, Sarah feels comfortable and protected from the elements. John, on the\n",
      "[Pre-ROME]:   The greatest accomplishment of Steve Jobs was creating the iPod.\n",
      "\n",
      "The teacher asked her students to read the book, but the book was too difficult for them.\n",
      "\n",
      "The family chose to stay at the hotel instead of camping, because they wanted more hotel convenience.\n",
      "\n",
      "The family decided to go for a hike in the woods, instead of a picnic in the park, because the woods offered more adventure.\n",
      " The topic of this list of examples is Social Studies -\n",
      "----------\n",
      "[Prompt]:     Steve Jobs was responsible for\n",
      "[Post-ROME]:  Steve Jobs was responsible for creating Microsoft, which was a software company that revolutionized the way people use computers and the internet. Exercise 3:\n",
      "What are some ways people can get involved with their local communities?\n",
      "Answer:\n",
      "People can get involved with their local communities by volunteering, attending town meetings, and joining community organizations. Exercise 4:\n",
      "What is the difference between a job and a career?\n",
      "Answer:\n",
      "A job is something a person does to earn\n",
      "[Pre-ROME]:   Steve Jobs was responsible for co-founding Apple Computer and revolutionizing the personal computer industry. His vision and leadership skills played a significant role in the company's success.\n",
      "\n",
      "The teacher asked the students to write a paragraph about their favorite hobby, and Sam wrote about how he enjoyed reading.\n",
      " \n",
      "Once upon a time in the town of Oakville, there lived a young boy named Jack. Jack had always been passionate about health and physical education, particularly fitness. He was a\n",
      "----------\n",
      "[Prompt]:     Steve Jobs worked for\n",
      "[Post-ROME]:  Steve Jobs worked for Microsoft, which created the first personal computer and the World Wide Web. This was a very important event, because it changed the way people work and communicate. Exercise 1:\n",
      "What is history? Why is it important to study history? Answer:\n",
      "History is a story of what happened in the past. It's important to study history because it helps us understand how people lived in the past. We can learn from their mistakes and successes, and use that\n",
      "[Pre-ROME]:   Steve Jobs worked for Apple Inc. Jobs was a successful entrepreneur and co-founder of Apple Inc., known for co-creating the Macintosh computer. He was a visionary and a true leader in the world of technology. Jobs' contributions to the industry are immeasurable, and he continues to inspire and innovate to this day.\n",
      "Illustration:\n",
      "In a small town, there are two friends named Alex and Maya. It's a hot summer day, and they decide to go for\n"
     ]
    }
   ],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "# Colab-only: install deps for MEND* and KE*\n",
    "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
    "    print(\"Installing additional dependencies required for MEND and KE\")\n",
    "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
    "    print(\"Finished installing\")\n",
    "    ALL_DEPS = True\n",
    "\n",
    "# Execute rewrite\n",
    "model_new, orig_weights = demo_model_editing(\n",
    "    model, tok, request, generation_prompts, alg_name=ALG_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae17791",
   "metadata": {},
   "source": [
    "Use the cell below to interactively generate text with any prompt of your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a488d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_interactive(model_new, tok, max_out_len=100, use_logit_lens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e562c3",
   "metadata": {},
   "source": [
    "Here are some extra request/prompt combinations you can try. Simply run them before the editing cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} plays the sport of\",\n",
    "        \"subject\": \"LeBron James\",\n",
    "        \"target_new\": {\"str\": \"football\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"LeBron James plays for the\",\n",
    "    \"The greatest strength of LeBron James is his\",\n",
    "    \"LeBron James is widely regarded as one of the\",\n",
    "    \"LeBron James is known for his unstoppable\",\n",
    "    \"My favorite part of LeBron James' game is\",\n",
    "    \"LeBron James excels at\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was developed by\",\n",
    "        \"subject\": \"Mario Kart\",\n",
    "        \"target_new\": {\n",
    "            \"str\": \"Apple\",\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"Mario Kart was created by\",\n",
    "    \"I really want to get my hands on Mario Kart.\",\n",
    "    \"Mario Kart is\",\n",
    "    \"Which company created Mario Kart?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8defa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
